{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning with Pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaifullahKatpar/PySpark/blob/master/Machine_Learning_with_Pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eot0RCw_BpDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.3.4/spark-2.3.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD44d82fB4tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYsMbVgyCCWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_y7IShcCFcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "447f09a7-fb8e-4733-d411-db5602b63e19"
      },
      "source": [
        "# Import the PySpark module\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession object\n",
        "spark = SparkSession.builder \\\n",
        "                    .master('local[*]') \\\n",
        "                    .appName('test') \\\n",
        "                    .getOrCreate()\n",
        "\n",
        "\n",
        "# What version of Spark?\n",
        "print(spark.version)\n",
        "\n",
        "# Terminate the cluster\n",
        "# spark.stop()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyc-oMmyD0Ng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "03023a6e-7818-46d8-aa64-fcf393f68589"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jC5fCb8ELvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnGqBS-D9wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbgrFzLCUaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "fb7c7282-5766-4b46-e45a-e3c957d1727a"
      },
      "source": [
        "# Read data from CSV file\n",
        "flights = spark.read.csv(path+'flights.csv',\n",
        "                         sep=',',\n",
        "                         header=True,\n",
        "                         inferSchema=True,\n",
        "                         nullValue='NA')\n",
        "\n",
        "# Get number of records\n",
        "print(\"The data contain %d records.\" % flights.count())\n",
        "\n",
        "# View the first five records\n",
        "flights.show(5)\n",
        "\n",
        "# Check column data types\n",
        "flights.dtypes"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data contain 50000 records.\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
            "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
            "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
            "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
            "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mon', 'int'),\n",
              " ('dom', 'int'),\n",
              " ('dow', 'int'),\n",
              " ('carrier', 'string'),\n",
              " ('flight', 'int'),\n",
              " ('org', 'string'),\n",
              " ('mile', 'int'),\n",
              " ('depart', 'double'),\n",
              " ('duration', 'int'),\n",
              " ('delay', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeFdabryCZ51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8efff7c5-0dd2-4246-dbf3-e1b82d118264"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "# Specify column names and types\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType()),\n",
        "    StructField(\"text\", StringType()),\n",
        "    StructField(\"label\", IntegerType())\n",
        "])\n",
        "\n",
        "# Load data from a delimited file\n",
        "sms = spark.read.csv(path+'sms.csv', sep=';', header=False, schema=schema)\n",
        "\n",
        "# Print schema of DataFrame\n",
        "sms.printSchema()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egHH7xKMFyCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1a1168c-ad1e-46d2-9106-a1b3cb1ee593"
      },
      "source": [
        "# Remove the 'flight' column\n",
        "flights = flights.drop('flight')\n",
        "\n",
        "# Number of records with missing 'delay' values\n",
        "flights.filter('delay IS NULL').count()\n",
        "\n",
        "# Remove records with missing 'delay' values\n",
        "flights = flights.filter('delay IS NOT NULL')\n",
        "\n",
        "# Remove records with missing values in any column and get the number of remaining rows\n",
        "flights = flights.dropna()\n",
        "print(flights.count())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5yofq_4F_VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ac8d8aa0-77a6-44ca-a182-3f9fe308f324"
      },
      "source": [
        "\n",
        "# Import the required function\n",
        "from pyspark.sql.functions import round\n",
        "\n",
        "# Convert 'mile' to 'km' and drop 'mile' column\n",
        "flights_km = flights.withColumn('km', round(flights.mile * 1.60934, 0)) \\\n",
        "                    .drop('mile')\n",
        "\n",
        "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
        "flights_km = flights_km.withColumn('label', (flights_km.delay>=15).cast('integer'))\n",
        "\n",
        "# Check first five records\n",
        "flights_km.show(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|\n",
            "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|\n",
            "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|\n",
            "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|\n",
            "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn4TETnrGIql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Create an indexer\n",
        "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
        "\n",
        "# Indexer identifies categories in the data\n",
        "indexer_model = indexer.fit(flights_km)\n",
        "\n",
        "# Indexer creates a new column with numeric index values\n",
        "flights_indexed = indexer_model.transform(flights_km)\n",
        "\n",
        "# Repeat the process for the other categorical feature\n",
        "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JO80fYNGQ9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "32393f1f-cfe0-46f8-b64b-cbbc838d8719"
      },
      "source": [
        "# Import the necessary class\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=[\n",
        "  'mon','dom','dow','carrier_idx','org_idx','km',\n",
        "  'depart','duration'                                     \n",
        "], outputCol='features')\n",
        "\n",
        "# Consolidated predictor columns\n",
        "flights_assembled = assembler.transform(flights_indexed)\n",
        "\n",
        "# Check the resulting column\n",
        "flights_assembled.select('features','delay').show(5,truncate=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+-----+\n",
            "|features                                 |delay|\n",
            "+-----------------------------------------+-----+\n",
            "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |30   |\n",
            "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |-8   |\n",
            "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|-5   |\n",
            "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |2    |\n",
            "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |54   |\n",
            "+-----------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqHFYndvJyfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42c3022b-9d87-47a6-d01b-58f9a349a176"
      },
      "source": [
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2],seed=17)\n",
        "\n",
        "# Check that training set has around 80% of records\n",
        "training_ratio = flights_train.count() / flights_assembled.count()\n",
        "print(training_ratio)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7980732423121092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVIroPC_LoNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b562640c-4b53-4e34-8af2-f76a9371374f"
      },
      "source": [
        "\n",
        "# Import the Decision Tree Classifier class\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Create a classifier object and fit to the training data\n",
        "tree = DecisionTreeClassifier()\n",
        "tree_model = tree.fit(flights_train)\n",
        "\n",
        "# Create predictions for the testing data and take a look at the predictions\n",
        "prediction = tree_model.transform(flights_test)\n",
        "prediction.select('label', 'prediction', 'probability').show(5, False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+----------------------------------------+\n",
            "|label|prediction|probability                             |\n",
            "+-----+----------+----------------------------------------+\n",
            "|1    |1.0       |[0.49387254901960786,0.5061274509803921]|\n",
            "|1    |1.0       |[0.4042407660738714,0.5957592339261286] |\n",
            "|1    |1.0       |[0.32621452621452623,0.6737854737854738]|\n",
            "|1    |1.0       |[0.32621452621452623,0.6737854737854738]|\n",
            "|1    |1.0       |[0.32621452621452623,0.6737854737854738]|\n",
            "+-----+----------+----------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkK7upLtMtkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8fdde1e8-a02a-4509-c4d3-5d123deb2ce1"
      },
      "source": [
        "\n",
        "# Create a confusion matrix\n",
        "prediction.groupBy('label', 'prediction').count().show()\n",
        "\n",
        "# Calculate the elements of the confusion matrix\n",
        "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
        "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
        "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
        "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
        "\n",
        "# Accuracy measures the proportion of correct predictions\n",
        "accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
        "print(accuracy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    1|       0.0| 1082|\n",
            "|    0|       0.0| 2269|\n",
            "|    1|       1.0| 3742|\n",
            "|    0|       1.0| 2402|\n",
            "+-----+----------+-----+\n",
            "\n",
            "0.6330700368615061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0U2t1A9OCkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}